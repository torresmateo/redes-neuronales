{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQgQ_DIhNDWS"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/torresmateo/redes-neuronales/blob/master/Clase_1/MNIST.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Clasificación de Imágenes MNIST\n",
    "\n",
    "El [MNIST](http://yann.lecun.com/exdb/mnist/) es una base de datos considerada como el \"Hello World\" del problema de clasificación de imágenes. Consta de 60000 ejemplos de *training* y 10000 ejemplos de *testing*. \n",
    "\n",
    "El problema es detectar y asignar un número digital a una imágen que contiene un número escrito a mano.\n",
    "\n",
    "En este notebook se implementa una red neuronal simple que es bastante eficáz para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h78yoLmnMrhk"
   },
   "outputs": [],
   "source": [
    "# Se incluyen las bibliotecas necesarias\n",
    "%tensorflow_version 2.x\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQ8uMWBPQDvM"
   },
   "source": [
    "# Descargar y explorar el *dataset* \n",
    "\n",
    "Al ser tan famoso, MNIST es un *dataset* que viene incluido en la instalación de TensorFlow, y particularmente [`keras`](https://keras.io/), un API que permite a los programadores contruir redes neuronales con agilidad, pues ya cuenta con unidades frecuentemente usadas y permite crear arquitecturas de red de forma ordenada y fácil.\n",
    "\n",
    "Primero que nada, cargamos el *dataset* a la memoria. Keras ya provee una partición conveniente en *training* y *testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EoRPBoRLQAA-",
    "outputId": "354fa286-d7f8-4de3-fa11-836c5339e439"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n81O76-mRHoh"
   },
   "source": [
    "Podemos explorar algunas dimensiones del *dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9ikMDcGBRGcK",
    "outputId": "774d7d5f-d230-4de3-fc1f-c14fdb88bf27"
   },
   "outputs": [],
   "source": [
    "print('imágenes de training:', train_images.shape[0])\n",
    "print('imágenes de testing:', test_images.shape[0])\n",
    "print('resolución de cada imagen:', train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5eI6fpzRgnw"
   },
   "source": [
    "Y visualizar algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "AMJuusoVRPpD",
    "outputId": "17b95d11-dec2-4f01-ddfd-610129b5a883"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(train_images[i], cmap='gray_r')\n",
    "    plt.xlabel(train_labels[i])\n",
    "    plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtK0reb_TzTE"
   },
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "Si bien es claro que las imágenes que tenemos son correctas, cuando estamos lidiando con redes neuronales es importante tener en cuenta el *rango* de los valores que se pasan a las neuronas artificiales. Por lo general, es bueno **estandarizar** los datos a un rango entre 0 a 1, pues muchas de las funciones de activación funcionan mejor en ese rango. \n",
    "\n",
    "Vamos a ver el rango actual de una de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_JdFBw32Rp1h",
    "outputId": "e0613cf3-0c0b-480c-9087-52c9867ed80d"
   },
   "outputs": [],
   "source": [
    "print(f'rango de valores en una imagen: ({np.min(train_images[0])}, {np.max(train_images[0])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1PtmcnqU8MP"
   },
   "source": [
    "el rango actual va de 0 a 255. Este rango no es adecuado para una función de activación como la sigmoide, ya que se saturaría muy rápidamente, y la calidad de nuestras predicciones se verá afectada. \n",
    "\n",
    "Por esto, normalizamos las imagens de nuestro *dataset* de tal manera que esten entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gz9Ran_UwLC"
   },
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHA8Mw-FVlXI"
   },
   "source": [
    "volvemos a verificar que el rango sea el deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EPVQr93MVfDH",
    "outputId": "8992354f-56fa-4bf0-eb9f-d4764bf560ad"
   },
   "outputs": [],
   "source": [
    "print(f'rango de valores en una imagen: ({np.min(train_images[0])}, {np.max(train_images[0])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWEi6IdpVsbz"
   },
   "source": [
    "No es necesario normalizar los *labels* en este caso, ya que al ser un problema de clasificación, basta que se cuente con la misma cantidad de valores diferentes con que se cuenta en el programa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXQF0i9QV8JK"
   },
   "source": [
    "# Diseño del modelo\n",
    "\n",
    "Vamos a crear una red neuronal simple de 3 *layers* (o capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQGL8ko2Vn6f"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                             tf.keras.layers.Dense(100, activation='relu'),\n",
    "                             tf.keras.layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFYA6lz-Wf-A"
   },
   "source": [
    "nuestro modelo se arma de la siguiente manera:\n",
    "\n",
    "**Sequential**: indica que nuestro modelo es una secuencia de *layers* conectados unos a otros.\n",
    "\n",
    "**Flatten**: es un tipo de *layer*, cuya función es \"aplanar\" los valores de entrada. En este caso, indicamos que se recibirá una matriz de dos dimensiones (28x28), y el resultante será un vector unidimensional de 784 valores.\n",
    "\n",
    "**Dense**: es el tipo de *layer* que vamos a utilizar. Agrega la cantidad de neuronas indicadas, que estan \"densamente\" o \"totalmente\" conectadas a las neuronas del *layer* anterior.\n",
    "\n",
    "**relu** indica que la función que se va a usar es un rectificador lineal, que implementa la siguiente función:\n",
    "```python\n",
    "def relu(x):\n",
    "    return max(x, 0)\n",
    "```\n",
    "esta es la función que cada neurona artificial de este *layer* va a ejecutar a la combinación lineal de sus valores de entrada.\n",
    "\n",
    "Finalmente **softmax** es una función de activación cuya función es asegurar que los valores del output de todas las neuronas de este *layer* sumen 1, y mantengan su proporción relativa. En términos simples, distribuye los outputs reflejando una probabilidad para cada neurona del *layer*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zd5fzUsAY3od"
   },
   "source": [
    "# Entrenamiento del modelo\n",
    "\n",
    "con el modelo definido, es hora de entrenar el modelo con los datos del *training set*. Para esto, es necesario utilizar la función `model.compile` para definir una función de optimización que guiará el aprendizaje de los coeficientes de la red. Además, se debe definir una función de costo que será minimizada por al función de optimización.\n",
    "\n",
    "En este caso, utilizaremos `adam`, un popular optimizador. La función de costo será `sparse_categorical_crossentropy`, una función de costo optimizada para problemas de clasificación con muchos *labels*.\n",
    "\n",
    "Finalmente, agregamos una métrica para medir calidad del modelo: `accuracy` (precisión)\n",
    "\n",
    "Una vez definidos estos parámetros, se utiliza la función `model.fit` para entrenar el modelo usando los datos. Aquí, `epoch` (épocas) se refiere a la cantidad de veces que el modelo será expuesto a los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "vNpSqRatYyVs",
    "outputId": "a3486288-15ef-4be7-9bec-9cba2b3fb428"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1Sf_qXjbpdq"
   },
   "source": [
    "# Evaluación del modelo\n",
    "\n",
    "Con el modelo entrenado, es hora de evaluarlo utilizando ejemplos que el modelo no ha visto (el *testing set*). Veremos que los resultados serán diferentes para datos no vistos por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Uj-WYh0CbTtv",
    "outputId": "59565d8b-92b0-4a72-c191-bbf56926f208"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAKnd-apb_1-"
   },
   "source": [
    "La diferencia entre los resultados de *training* y *testing* se debe a algo conocido como *overfitting*. Este es un problema complejo, pero existen técnicas prácticas para minimizar el *overfitting* que veremos más adelante.\n",
    "\n",
    "Por el momento, analicemos los casos en que nuestro modelo no reconoce correctamente a los números. Primero, definamos una función que nos permitirá entender mejor el *output* de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYfTTr_FeQWd"
   },
   "outputs": [],
   "source": [
    "def ver_imagen(test_dataset, test_labels, predicciones, indice):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(test_dataset[indice], cmap='gray_r')\n",
    "    prediccion = np.argmax(predicciones[indice])\n",
    "    col = 'green' if prediccion == test_labels[indice] else 'red'\n",
    "    plt.xlabel(f'pred: {prediccion} ({100*np.max(predicciones[indice]):2.0f}%), val: {test_labels[indice]}',\n",
    "               color=col)\n",
    "\n",
    "def ver_prediccion(test_labels, predicciones, indice):\n",
    "    plt.grid(False)\n",
    "    plt.yticks([])\n",
    "    plt.xticks(range(10))\n",
    "    bars = plt.bar(range(10), predicciones[indice], color='gray')\n",
    "    prediccion = np.argmax(predicciones[indice])\n",
    "    bars[prediccion].set_color('red')\n",
    "    bars[test_labels[indice]].set_color('green')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "colab_type": "code",
    "id": "hvfql0hVcyse",
    "outputId": "556cceec-16c4-46c6-c797-81b831c69382"
   },
   "outputs": [],
   "source": [
    "# obtenemos las predicciones para todos los ejemplos del testing set\n",
    "predicciones = model.predict(test_images)\n",
    "# la predicción seleccionada corresponde al índice de la lista que contiene el mayor valor\n",
    "labels_pred = np.argmax(predicciones, axis=1)\n",
    "\n",
    "# como sabemos los labels reales, es fácil identificar los valores que nuestro modelo no predice correctamente\n",
    "# simplemente identificamos los ejemplos en que nuestro modelo difiere del valor real\n",
    "errores = np.where(labels_pred != test_labels)[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 6, 2*i+1)\n",
    "    ver_imagen(test_images, test_labels, predicciones, errores[i])\n",
    "    plt.subplot(3, 6, 2*i+2)\n",
    "    ver_prediccion(test_labels, predicciones, errores[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNVxonPxcWX7"
   },
   "source": [
    "# Puesta en producción del modelo\n",
    "\n",
    "El modelo que entrenamos más arriba puede ser mejorado considerablemente (estás invitado a usar este notebook para modificar el modelo y probar como mejorar el modelo!). \n",
    "\n",
    "Por el momento, pretendamos que estamos contentos con la precisión de nuestro modelo, y veamos como podemos usarlo \"en la vida real\"\n",
    "\n",
    "Vamos a usar una [herramienta online](https://mnist-demo.herokuapp.com/) para dibujar números con el mouse y ver como nuestro modelo clasifica dichas imágenes.\n",
    "\n",
    "**Nota:** Este código es específico para Google Colab, y si quiere probarlo en su computadora local, debe cambiar el código que accede a las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "bn92Fg4tb8q-",
    "outputId": "d82ff5e7-dc99-467b-d408-ac2ee9dc37b6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# subimos las imágenes a nuestra instancia de Google Colab\n",
    "uploaded = files.upload()\n",
    "cant_imgs = len(uploaded.keys())\n",
    "plt.figure(figsize=(4,2*cant_imgs))\n",
    "for i, fn in enumerate(uploaded.keys()):\n",
    " \n",
    "    # prediciendo imágenes subidas\n",
    "    directorio = '/content/' + fn\n",
    "    imagen = image.load_img(directorio, target_size=(28, 28), color_mode='rgba')\n",
    "    x = image.img_to_array(imagen)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x/255.0 #  normalizamos el array para nuestro modelo\n",
    "    images = np.vstack([x[:,:,:,3]])\n",
    "    prediccion = model.predict(images, batch_size=10)\n",
    "    valor = np.argmax(prediccion[0])\n",
    "    plt.subplot(cant_imgs, 2, 2*i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(images[0],cmap='gray_r')\n",
    "    plt.xlabel(f'pred: {valor} ({100*np.max(prediccion[0]):2.0f}%)')\n",
    "    plt.subplot(cant_imgs, 2, 2*i+2)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    plt.bar(range(10), prediccion[0], color='gray')\n",
    "    #print(np.argmax(classes[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vO0ae_40nJg2"
   },
   "source": [
    "# Créditos \n",
    "\n",
    "Este notebook utiliza y modifica recursos del [tutorial de TensorFlow](https://www.tensorflow.org/tutorials/keras/classification) y está inspirado en contenido del curso online [TensorFlow in Practice](https://www.deeplearning.ai/tensorflow-in-practice/). Agradecimientos a [Shafeen Tejani](https://github.com/ShafeenTejani) por su implementación interactiva de MNIST."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Clase 1] 2 - MNIST",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
